/home/stanlo229/anaconda3/envs/MolFoundation/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
/home/stanlo229/anaconda3/envs/MolFoundation/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Epoch 0
num_of_examples 1 loss: 0.00018929308280348777 %_data_trained : 0.0
/home/stanlo229/Research/Repos/MolFoundation/t5-chem/data_utils.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  "y_regression_values": torch.tensor(self.y_regression_values[idx]).to(self.device),
num_of_examples 401 loss: 0.00361056724563241 %_data_trained : 5.0
num_of_examples 801 loss: 0.0025856876466423275 %_data_trained : 10.0
num_of_examples 1201 loss: 0.0018888947367668152 %_data_trained : 15.0
num_of_examples 1601 loss: 0.0013572309538722037 %_data_trained : 20.0
num_of_examples 2001 loss: 0.0010609905258752406 %_data_trained : 25.0
num_of_examples 2401 loss: 0.000977839359547943 %_data_trained : 30.0
num_of_examples 2801 loss: 0.0006841328809969127 %_data_trained : 35.0
num_of_examples 3201 loss: 0.0006710814009420574 %_data_trained : 40.0
num_of_examples 3601 loss: 0.0005457377794664353 %_data_trained : 45.0
num_of_examples 4001 loss: 0.0004522612830623984 %_data_trained : 50.0
num_of_examples 4401 loss: 0.0003717576328199357 %_data_trained : 55.00000000000001
num_of_examples 4801 loss: 0.00034418894443660975 %_data_trained : 60.0
num_of_examples 5201 loss: 0.00022901380434632302 %_data_trained : 65.0
num_of_examples 5601 loss: 0.00019356481585418805 %_data_trained : 70.0
num_of_examples 6001 loss: 0.00015633484988939017 %_data_trained : 75.0
num_of_examples 6401 loss: 0.00018398159241769462 %_data_trained : 80.0
num_of_examples 6801 loss: 0.00015995191119145603 %_data_trained : 85.0
num_of_examples 7201 loss: 0.00013795912964269518 %_data_trained : 90.0
num_of_examples 7601 loss: 0.00014287973128375596 %_data_trained : 95.0
Traceback (most recent call last):
  File "/home/stanlo229/Research/Repos/MolFoundation/t5-chem/run_script.py", line 168, in <module>
    outputs_dict = inference_test_set(epoch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stanlo229/Research/Repos/MolFoundation/t5-chem/run_script.py", line 129, in inference_test_set
    total_loss += nn_loss.item()
    ^^^^^^^^^^
UnboundLocalError: cannot access local variable 'total_loss' where it is not associated with a value